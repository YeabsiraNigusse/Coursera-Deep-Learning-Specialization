{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YeabsiraNigusse/Deep_Learning/blob/main/Deep%20Learning%20Notes/Deep%20Learning%20Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep Learning Notes"
      ],
      "metadata": {
        "id": "2JwI9MqOVGG8"
      },
      "id": "2JwI9MqOVGG8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### soft max function\n",
        "\n",
        "it is a function used to calculate the class probability of a given input.\n",
        "\n",
        "for example if i have a model that classifies spar or not spam and if the model give me row score(number) for each class(spam or not spam) then soft max calculate the given number and give me the probability distrbution for each class"
      ],
      "metadata": {
        "id": "EDbBYIaLtd_i"
      },
      "id": "EDbBYIaLtd_i"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>\n",
        "<b>What i need to remember:</b>\n",
        "    \n",
        "- np.exp(x) works for any np.array x and applies the exponential function to every coordinate. better than math.exp() which needs nested for loop\n",
        "- the sigmoid function and its gradient: i can use numpy `np.exp(0)` to calculate sigmoid and its gradient for single number or martrics or an array of numpy with brodcasting(meaning for each element with out using nested loop)\n",
        "- image2vector is commonly used in deep learning: i can use `np.reshape(v.shape[0]*v.shape[1], 1)` to covert 2D into 1D\n",
        "- numpy has efficient built-in functions like the above ones\n",
        "- broadcasting is extremely useful"
      ],
      "metadata": {
        "id": "2uv4WVKcuvtZ"
      },
      "id": "2uv4WVKcuvtZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logestic regression as Nural Network\n",
        "\n",
        "we have multiple cat images we want to know that the probability of the picture is cat or not\n",
        "\n",
        "Notations\n",
        "\n",
        "- X represent `Green * Red * Blue * 3(n)` by `m` which is number of traing examples\n",
        "\n",
        "i understand that logestic regression works for cat image classification by learning from pixle size. if w*x + b is large it shows the high probability of the image is a cat and viceverse."
      ],
      "metadata": {
        "id": "1sTRVASAkp4k"
      },
      "id": "1sTRVASAkp4k"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps\n",
        "\n",
        "- find Z = W*x + B\n",
        "- find sigmoid(Z)\n",
        "- find loss function using result of sigmoid(Z) and ground truth label\n",
        "- find the derivative of dw and db from the loss function\n",
        "- update w and b using learning rate , dw and db with specific number of iterations"
      ],
      "metadata": {
        "id": "ZPI_c3-4BaC6"
      },
      "id": "ZPI_c3-4BaC6"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TwmyubSwVJnR"
      },
      "id": "TwmyubSwVJnR",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}